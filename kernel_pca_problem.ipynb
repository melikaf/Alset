{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kernel_pca_problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "r4-0E7wHNuY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Kernel PCA\n"
      ]
    },
    {
      "metadata": {
        "id": "5-ZxMjkDy2Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "There is another type of PCA  method for non-linear dimensionality reduction through the use of kernels. There is a class in sklearn library for implementing Kernel PCA. You can read more about how to use that and the parameters [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html).\n",
        "\n",
        "\n",
        "\n",
        "EXAMPLE 1:\n",
        "```\n",
        "  num_of_components = 1\n",
        "  pca = KernelPCA(n_components = num_of_components, kernel='rbf') #the kernel can be poly, linear, rbf\n",
        "  x = pca.fit_transform(x)\n",
        "```\n",
        "\n",
        "\n",
        "Now is your turn!\n",
        "\n",
        "Change the kernel_pca_function to takes in an input x that is a dataframe and run the PCA algorithm with 2 components and try to use different values for kernel. Please note that it is very important to normalize the data before running the PCA algorithm. You can run without normailzation and run again after normalization with different kernel types aand observe the changes.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZT4C2hLTyB7i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#problem\n",
        "def kernel_pca_function(x):\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from sklearn.decomposition import KernelPCA\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XHoIisrPyB8A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Tests \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "import random\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "df = datasets.load_wine()\n",
        "x = df.data\n",
        "y = df.target\n",
        "x = kernel_pca_function(x)\n",
        "\n",
        "plt.scatter(x[y == 0, 0], x[y == 0, 1],  c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(x[y == 1, 0], x[y == 1, 1], c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(x[y == 2, 0], x[y == 2, 1],  c = 'green', label = 'Cluster 3')\n",
        "plt.title('PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gagVbfCOyB8L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert x.shape[1]== 2 ,'Dimensions not reduced properly'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}